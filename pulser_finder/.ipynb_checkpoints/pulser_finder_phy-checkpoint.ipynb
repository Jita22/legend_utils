{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0d77574-59b7-472f-846b-044430941dd9",
   "metadata": {},
   "source": [
    "# Extracting the pulser position for each channel from the physics hit file\n",
    "Jita (21 Jan 2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f1749c-5a6e-46b5-9d56-37182f8a45cd",
   "metadata": {},
   "source": [
    "Due to low statistics for the physics files, it should be possible to extract the position of the pulser for each channel, byt looking at the signal that comes most frequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec67b971-df6e-4cb3-be1f-5297a7692a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading hit files\n",
    "def load_hit(file):\n",
    "    return lh5.load_dfs(file, ['cuspEmax_ctc_cal'], f\"ch{ch}/hit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e093ef6-d308-4777-9150-074e1dcc7e82",
   "metadata": {},
   "source": [
    "#### Load the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6549043-4c18-4002-8f46-378855842006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pygama.lgdo.lh5_store as lh5 \n",
    "from lgdo import LH5Store\n",
    "from legendmeta import LegendMetadata\n",
    "\n",
    "import glob\n",
    "\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "from scipy import optimize\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "import matplotlib as mpl\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from matplotlib import ticker\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ebaba8-c7c9-484b-a26e-5f3d382d0fe7",
   "metadata": {},
   "source": [
    "#### Find and list all the files that are available in a period_run\n",
    "This needs to be sorted!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e99d35cd-b98c-45b5-8292-beafe1709e11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['r000', 'r001', 'r002', 'r003', 'r004', 'r005']]\n"
     ]
    }
   ],
   "source": [
    "# Selecting the data\n",
    "expt = \"l200\"\n",
    "data_type = \"phy\"\n",
    "periods = [\"p03\"]\n",
    "runs = []\n",
    "\n",
    "# Append runs to the array\n",
    "for data_period in periods:\n",
    "    runs_temp = sorted(glob.glob(f\"/global/cfs/cdirs/m2676/data/lngs/l200/public/prodenv/prod-blind/ref/v02.00/generated/tier/pht/{data_type}/{data_period}/*\"))\n",
    "    runs.append([x[-4:] for x in runs_temp])\n",
    "    print(runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b71fea9-0510-4c63-b628-4f476b7e0ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated runs: [['r000', 'r001', 'r002', 'r003', 'r004', 'r005']]\n"
     ]
    }
   ],
   "source": [
    "# Remove problematic runs from the array\n",
    "for data_period, xy in zip(periods, runs):\n",
    "    runs_to_remove = []  # To store indices of runs to be removed\n",
    "\n",
    "    for i, data_run in enumerate(xy):\n",
    "        hit_file = sorted(glob.glob(f\"/global/cfs/cdirs/m2676/data/lngs/l200/public/prodenv/prod-blind/ref/v02.00/generated/tier/pht/{data_type}/{data_period}/{data_run}/{expt}-{data_period}-{data_run}-{data_type}-*-tier_pht.lh5\"))\n",
    "        \n",
    "        if not (hit_file):\n",
    "            print(f\"Issue: Files not found for {data_period}, {data_run}\")\n",
    "            runs_to_remove.append(i)\n",
    "\n",
    "    # Remove runs with issues\n",
    "    for index in reversed(runs_to_remove):\n",
    "        xy.pop(index)\n",
    "\n",
    "print(\"Updated runs:\", runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84101f37-b9ae-4457-bf4a-2192f2648d18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/global/cfs/cdirs/m2676/data/lngs/l200/public/prodenv/prod-blind/ref/v02.00/generated/tier/pht/phy/p03/r000/l200-p03-r000-phy-20230312T043356Z-tier_pht.lh5 149\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dsp_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 10\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 10\u001b[0m     dt \u001b[38;5;241m=\u001b[39m hit_file[\u001b[38;5;241m0\u001b[39m][hit_file[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-cal-\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-cal-\u001b[39m\u001b[38;5;124m\"\u001b[39m):hit_file[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-tier_\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: substring not found",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m     dt \u001b[38;5;241m=\u001b[39m hit_file[\u001b[38;5;241m0\u001b[39m][hit_file[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-cal-\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-cal-\u001b[39m\u001b[38;5;124m\"\u001b[39m):hit_file[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-tier_\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m---> 12\u001b[0m     dt \u001b[38;5;241m=\u001b[39m hit_file[\u001b[38;5;241m0\u001b[39m][dsp_file[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-phy-\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-phy-\u001b[39m\u001b[38;5;124m\"\u001b[39m):hit_file[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-tier_\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Making a dictionary for each of the systems\u001b[39;00m\n\u001b[1;32m     15\u001b[0m lmeta \u001b[38;5;241m=\u001b[39m LegendMetadata()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dsp_file' is not defined"
     ]
    }
   ],
   "source": [
    "# The Code for fitting\n",
    "for data_period,xy in zip(periods, runs):\n",
    "    for data_run in xy:\n",
    "        hit_file = sorted(glob.glob(f\"/global/cfs/cdirs/m2676/data/lngs/l200/public/prodenv/prod-blind/ref/v02.00/generated/tier/pht/{data_type}/{data_period}/{data_run}/{expt}-{data_period}-{data_run}-{data_type}-*-tier_pht.lh5\"))\n",
    "        \n",
    "        print(hit_file[0], len(hit_file))\n",
    "\n",
    "        # extracting the datetime stamp\n",
    "        try:\n",
    "            dt = hit_file[0][hit_file[0].index(\"-cal-\") + len(\"-cal-\"):hit_file[0].index(\"-tier_\")]\n",
    "        except:\n",
    "            dt = hit_file[0][hit_file[0].index(\"-phy-\") + len(\"-phy-\"):hit_file[0].index(\"-tier_\")]\n",
    "\n",
    "        # Making a dictionary for each of the systems\n",
    "        lmeta = LegendMetadata()\n",
    "        chmap = lmeta.hardware.configuration.channelmaps.on(dt)\n",
    "        geds_dict = {}\n",
    "        sipms_dict={}\n",
    "        auxs_dict={}\n",
    "\n",
    "        for channel_name, channel_data in chmap.items():\n",
    "            if (channel_data.system == \"geds\"):\n",
    "                geds_dict[channel_data[\"daq\"][\"rawid\"]] = (channel_name, channel_data.location.string, channel_data.location.position, lmeta.channelmap(dt)[channel_name].analysis.usability, lmeta.channelmap(dt)[channel_name].type, lmeta.channelmap(dt)[channel_name].production['mass_in_g'])\n",
    "            if (channel_data.system == \"spms\"):\n",
    "                sipms_dict[channel_data[\"daq\"][\"rawid\"]] = (channel_name)\n",
    "            if (channel_data.system == \"auxs\"):\n",
    "                auxs_dict[channel_data[\"daq\"][\"rawid\"]] = (channel_name)\n",
    "\n",
    "        geds_on = {}\n",
    "\n",
    "        for x in geds_dict:\n",
    "            if (geds_dict[x][3] == 'on'):\n",
    "                geds_on[x] = (geds_dict[x][0], geds_dict[x][1], geds_dict[x][2], geds_dict[x][3], geds_dict[x][4], geds_dict[x][5])\n",
    "\n",
    "        data = {}\n",
    "        for ch in list(geds_on.keys()):\n",
    "\n",
    "            df_hit={} #indexing for files\n",
    "\n",
    "            # Load in hit file\n",
    "            for i in range(len(hit_file)):\n",
    "                df_hit [i] = load_hit(hit_file[i])\n",
    "\n",
    "            # Make master hit files for each run\n",
    "            data[ch] = pd.concat(df_hit, verify_integrity=True)\n",
    "            #data [ch] = pd.merge(df_dsp_master, df_hit_master, left_index=True, right_index=True, how='left')\n",
    "            display(data[ch])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcd21aa-7bbe-4df0-9130-9512a9f5aaba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "legend-base",
   "language": "python",
   "name": "legend-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
